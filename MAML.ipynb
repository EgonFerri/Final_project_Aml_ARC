{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODULES IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np              #numpy library is used to work with multidimensional array.\n",
    "import pandas as pd             #pandas used for data manipulation and analysis.\n",
    "                 \n",
    "import os                       #os library is used for loading file to use in the program\n",
    "import json                     #json library parses json into a string or dict, and convert string or dict to json file.\n",
    "from pathlib import Path        #support path\n",
    "\n",
    "import matplotlib.pyplot as plt #support ploting a figure\n",
    "from matplotlib import colors   #colors support converting number or argument into colors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------\n",
    "## MAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam, Optimizer\n",
    "from pathlib import Path\n",
    "from os.path import join\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    tasks = []\n",
    "    for file_path in os.listdir(path):\n",
    "        task_file = join(path, file_path)\n",
    "\n",
    "        with open(task_file, 'r') as f:\n",
    "            task = json.load(f)\n",
    "            tasks.append(task)\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"./data\")\n",
    "train_tasks = load_data(path / 'training')\n",
    "evaluation_tasks = load_data(path /'evaluation')\n",
    "test_tasks = load_data(path / 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_padding(x):\n",
    "    x = torch.Tensor(x)\n",
    "    return nn.ConstantPad2d((floor((30 - x.shape[1])/2), floor((30 - x.shape[2])/2),\n",
    "                                       ceil((30 - x.shape[2])/2), ceil((30 - x.shape[1])/2)), 0)(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcData(Dataset):\n",
    "\n",
    "    def __init__(self, Xy, type_ = \"train\"):\n",
    "        \n",
    "        self.Xy = Xy\n",
    "        self.type = type_\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        Xy = self.Xy[idx][self.type]\n",
    "        X = [x[\"input\"] for x in Xy]\n",
    "        \n",
    "        if self.type == \"train\" or self.type == \"test\":\n",
    "            y = [y[\"output\"] for y in Xy]\n",
    "            return np.array(X), np.array(y)\n",
    "        else:\n",
    "            return np.array(X)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(x):\n",
    "    x = np.array(x)\n",
    "    if len(x.shape) != 2:\n",
    "        x = np.expand_dims(x, 1)\n",
    "    return x\n",
    "\n",
    "def pad(x):\n",
    "    img = np.array([np.zeros((x.shape[0], x.shape[1]))+i for i in range(10)])\n",
    "    img = (x-img == 0)*1\n",
    "    return img\n",
    "\n",
    "# def calk_score(predict, y):\n",
    "#     return [int(np.equal(y, predict).all())]\n",
    "\n",
    "def check_list(x):\n",
    "    types = [type(i) for arr in x for i in arr]\n",
    "    if any([types == [type(list()) for _ in range(len(types))]]):\n",
    "        x = np.array([np.array([el for el in i]) for i in x]).squeeze()\n",
    "    return x\n",
    "\n",
    "def shapes(x):\n",
    "    s = []\n",
    "    if str(x).isdigit() == False:\n",
    "        for arr in x:\n",
    "            s.append(arr.shape)\n",
    "    else:\n",
    "        s.append(1)\n",
    "    return s\n",
    "def input_output_shape_is_same(batch):\n",
    "    return all([np.array(el[\"input\"]).shape == np.array(el[\"output\"]).shape for el in batch[\"train\"]])\n",
    "def calk_score(task_test, predict):\n",
    "    return [int(np.equal(sample['output'], pred).all()) for sample, pred in zip(task_test, predict)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b11ab4c25d84115bfcc3c4a03eefb0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-560-d8d7f99a552c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     90\u001b[0m                 fast_weights = OrderedDict(\n\u001b[0;32m     91\u001b[0m                     \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0minner_lr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfast_weights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradients\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m                 )\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-560-d8d7f99a552c>\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     90\u001b[0m                 fast_weights = OrderedDict(\n\u001b[0;32m     91\u001b[0m                     \u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0minner_lr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfast_weights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradients\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m                 )\n\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def replace_grad(parameter_gradients, parameter_name):\n",
    "    \"\"\"Creates a backward hook function that replaces the calculated gradient\n",
    "    with a precomputed value when .backward() is called.\n",
    "    \n",
    "    See\n",
    "    https://pytorch.org/docs/stable/autograd.html?highlight=hook#torch.Tensor.register_hook\n",
    "    for more info\n",
    "    \"\"\"\n",
    "    def replace_grad_(module):\n",
    "        return parameter_gradients[parameter_name]\n",
    "\n",
    "    return replace_grad_\n",
    "\n",
    "class DummyModel(torch.nn.Module):\n",
    "    \"\"\"Dummy 1 layer (0 hidden layer) model for testing purposes\"\"\"\n",
    "    def __init__(self, k: int):\n",
    "        super(DummyModel, self).__init__()\n",
    "        self.out = nn.Conv2d(10, k,kernel_size = 5, padding = 2, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "    def functional_forward(self, x, weights):\n",
    "        x = F.conv2d(x, weights['out.weight'], padding = 2)\n",
    "        return x\n",
    "    \n",
    "def create_nshot_task_label(k: int, q: int, shape: int) -> torch.Tensor:\n",
    "    \"\"\"Creates an n-shot task label.\n",
    "    Label has the structure:\n",
    "        [0]*q + [1]*q + ... + [k-1]*q\n",
    "    # TODO: Test this\n",
    "    # Arguments\n",
    "        k: Number of classes in the n-shot classification task\n",
    "        q: Number of query samples for each class in the n-shot classification task\n",
    "    # Returns\n",
    "        y: Label vector for n-shot task of shape [q * k, ]\n",
    "    \"\"\"\n",
    "    y = torch.stack([torch.arange(0, shape, 1 / q).long()]).long()\n",
    "    return y\n",
    "\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "cuda_ = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda_ else \"cpu\")\n",
    "\n",
    "training_set = ArcData(train_tasks, \"train\")\n",
    "history = []\n",
    "\n",
    "result = []\n",
    "predictions = []\n",
    "\n",
    "model = DummyModel(10).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr = 0.1)\n",
    "data_shape = tuple((6,))\n",
    "inner_train_steps = 30\n",
    "order = 2\n",
    "train = True\n",
    "n_shot = 1\n",
    "inner_lr = 0.1\n",
    "create_graph = (True if order == 2 else False) and train\n",
    "\n",
    "\n",
    "task_predictions = []\n",
    "inputs, outputs = [] , []\n",
    "for batch in train_tasks:\n",
    "    if input_output_shape_is_same(batch):\n",
    "        batches_inp = []\n",
    "        batches_outp = []\n",
    "        for sample in batch[\"train\"]:\n",
    "            batches_inp.append(torch.Tensor(pad(np.array(sample[\"input\"]))))\n",
    "            batches_outp.append(torch.LongTensor(np.array(sample[\"output\"])))\n",
    "        inputs.append(batches_inp)\n",
    "        outputs.append(batches_outp)\n",
    " \n",
    "\n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    task_gradients = []\n",
    "    task_losses = []\n",
    "    for meta_batch_samples, meta_batch_labels in zip(inputs, outputs):\n",
    "        # By construction x is a 5D tensor of shape: (meta_batch_size, n*k + q*k, channels, width, height)\n",
    "        # Hence when we iterate over the first  dimension we are iterating through the meta batches\n",
    "        # Equivalently y is a 2D tensor of shape: (meta_batch_size, n*k + q*k, 1)\n",
    "        x_task_train = meta_batch_samples[:-2]\n",
    "        x_task_val = meta_batch_samples[-2:]\n",
    "        y_task_train = meta_batch_labels[:-2]\n",
    "        y_task_val = meta_batch_labels[-2:]\n",
    "        # Create a fast model using the current meta model weights\n",
    "        fast_weights = OrderedDict(model.named_parameters())\n",
    "\n",
    "\n",
    "        # Train the model for `inner_train_steps` iterations\n",
    "        for inner_batch in range(inner_train_steps):\n",
    "            for x,y in zip(x_task_train, y_task_train):\n",
    "            # Perform update of model weights\n",
    "                logits = model.functional_forward(torch.Tensor(x).unsqueeze(0).to(device), fast_weights)\n",
    "                loss = loss_fn(logits.to(device), y.unsqueeze(0).to(device))\n",
    "                gradients = torch.autograd.grad(loss, fast_weights.values(), create_graph=create_graph)\n",
    "                # Update weights manually\n",
    "                fast_weights = OrderedDict(\n",
    "                    (name, param - inner_lr * grad)\n",
    "                    for ((name, param), grad) in zip(fast_weights.items(), gradients)\n",
    "                )\n",
    "\n",
    "        # Do a pass of the model on the validation data from the current task\n",
    "        logits = []\n",
    "        losses = []\n",
    "        for x,y in zip(x_task_val, y_task_val):\n",
    "            lgt = model.functional_forward(torch.Tensor(x).unsqueeze(0).to(device), fast_weights)\n",
    "            logits.append(lgt)\n",
    "            loss = loss_fn(lgt.to(device), y.unsqueeze(0).to(device))\n",
    "            losses.append(loss)\n",
    "            loss.backward(retain_graph=True)\n",
    "        # Get post-update accuracies\n",
    "        task_predictions.append(logits)\n",
    "\n",
    "        # Accumulate losses and gradients\n",
    "        task_losses.append(torch.stack(losses))\n",
    "        gradients = torch.autograd.grad(losses, fast_weights.values(), create_graph=create_graph)\n",
    "        named_grads = {name: g for ((name, _), g) in zip(fast_weights.items(), gradients)}\n",
    "        task_gradients.append(named_grads)\n",
    "\n",
    "    if order == 1:\n",
    "        if train:\n",
    "            sum_task_gradients = {k: torch.stack([grad[k] for grad in task_gradients]).mean(dim=0)\n",
    "                                  for k in task_gradients[0].keys()}\n",
    "            hooks = []\n",
    "            for name, param in model.named_parameters():\n",
    "                hooks.append(\n",
    "                    param.register_hook(replace_grad(sum_task_gradients, name))\n",
    "                )\n",
    "\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            # Dummy pass in order to create `loss` variable\n",
    "            # Replace dummy gradients with mean task gradients using hooks\n",
    "            logits = model(torch.zeros((10, 1, ) + data_shape).unsqueeze(0).to(device))\n",
    "            loss = loss_fn(logits, create_nshot_task_label(1, 1, 6).unsqueeze(0).to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            for h in hooks:\n",
    "                h.remove()\n",
    "\n",
    "\n",
    "    elif order == 2:\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        meta_batch_loss = torch.stack([i for j in task_losses for i in j]).mean()\n",
    "        if train:\n",
    "            meta_batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for batch in train_tasks:\n",
    "    if input_output_shape_is_same(batch):\n",
    "        pred = []\n",
    "        for sample in batch[\"test\"]:\n",
    "            p = model(torch.Tensor(pad(np.array(sample[\"input\"]))).unsqueeze(0).to(device))\n",
    "            \n",
    "            pred.append(p)\n",
    "        predictions = [i.squeeze(0).cpu().detach().numpy().argmax(0) for j in pred for i in j]\n",
    "        score = calk_score(batch[\"test\"], predictions)\n",
    "        scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0, 0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0, 0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0, 0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0, 0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0, 0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0, 0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0],\n",
       " [0]]"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "# basic cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c23eef46414cfd8047222b3e51d9c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=400.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [1], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0, 0], [0], [0], [0], [1], [0, 0], [0], [0], [0, 0, 0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0, 0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0, 0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0, 0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0, 0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [1], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0, 0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [1], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0, 0], [0], [0], [0], [0, 0], [0], [0], [0], [0], [0], [0], [0], [0], [0, 0], [0], [0], [0], [0], [0], [0, 0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0, 0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0], [0, 0, 0], [0]]\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "correct = []\n",
    "val_set = ArcData(train_tasks, \"test\")\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "cuda_ = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if cuda_ else \"cpu\")\n",
    "device = \"cpu\"\n",
    "\n",
    "training_set = ArcData(train_tasks, \"train\")\n",
    "history = []\n",
    "\n",
    "result = []\n",
    "predictions = []\n",
    "for batch in tqdm(train_tasks):\n",
    "    if input_output_shape_is_same(batch):\n",
    "        net = DummyModel(10).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = Adam(net.parameters(), lr = 0.1)\n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            for sample in batch[\"train\"]:\n",
    "                #print(sample)\n",
    "                \n",
    "                x = expand(sample[\"input\"])\n",
    "                y = expand(sample[\"output\"])\n",
    "\n",
    "                padded_x = pad(x)\n",
    "\n",
    "                inputs = torch.Tensor(padded_x).unsqueeze(0).to(device)\n",
    "                outputs = torch.LongTensor(y).unsqueeze(0).to(device)\n",
    "#                 meta_gradient_step(net, optimizer, criterion, inputs, outputs, 10, 5, 1, 10, 0.1, True, device)\n",
    "                optimizer.zero_grad()\n",
    "                out = net(inputs)\n",
    "                loss = criterion(out, outputs)\n",
    "                history.append(loss)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        p = []\n",
    "        with torch.no_grad():\n",
    "            for sample in batch[\"test\"]:\n",
    "                x = sample[\"input\"]\n",
    "                y = sample[\"output\"]\n",
    "                #print(sample)\n",
    "                x = expand(x)\n",
    "                y = expand(y)\n",
    "    #                 x = check_list(x)\n",
    "    #                 y = check_list(y)\n",
    "\n",
    "    #             shapes_x = shapes(x)\n",
    "    #             shapes_y = shapes(y)\n",
    "\n",
    "    #             if all([shapes_x == shapes_y]):\n",
    "\n",
    "                padded_x = pad(x)\n",
    "\n",
    "                inputs = torch.FloatTensor(padded_x).unsqueeze(0).to(device)\n",
    "\n",
    "                pred = net(inputs)\n",
    "\n",
    "                pred = pred.squeeze(dim = 0).cpu().numpy().argmax(0)\n",
    "                p.append(pred)\n",
    "        score = calk_score(batch['test'], p)\n",
    "                \n",
    "    else:\n",
    "        pred = [el['input'] for el in batch['test']]\n",
    "        score = [0]*len(batch['test'])\n",
    "    predictions.append(pred)\n",
    "    result.append(score)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAFFCAYAAAAetc9nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAHsAAAB7AB1IKDYgAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAXmklEQVR4nO3df6zddX3H8ecbCSO5qSJoZrFgRzRzjWRZQvxtxopyR6I21Ml0RiggTVMDDY1QtZoYEzrWLW1mFQGp3CkFpK46IODVWdymWfaHukRmMmNIaytzJCCmQVes970/zrnb6fHe2/s99/s953s+9/lIbjj9fs/3+37fe998Xvf8+N4bmYkkSSrDaaNuQJIk1cdglySpIAa7JEkFMdglSSrI6VXuHBErgZ3ADHB3Zn6rZ98U8GvgN8CWzDxeX5uS1G6uj2qLSsEOfADYAfwncA/wrZ59vwJeADwNPF9Hc5I0Rlwf1QrzBntEXAj8Zd/mnwJHMnMmIvoP+WB3+w3AZcAjPeeaBCaBG2vpeshuvHrUHVS3++5RdzCwA5n5rmEUescZb8nzT3vZMEoN3W3HvzzqFkox5zw2sj6e+0c3svIP6+1+GL47NeoOlpNFrY/zBntm/gB4e++2iPg4sCoifjTH/We6N58CVvTtmwamI2Isg33X9lF3UN0YB/vhYRU6/7SXsWNi87DKDZXBXps557GR9fGiq2/kTz5SS9NDZbAP06LWx6pPxe8FbgVOAHdB57WjzNwQEbuAM4EXA9dWPK8kjTvXR7VCpWDPzCeBK/u2bej+d2t9bUnSeHF9VFt4uZskSQUx2CVJKojBLklSQQx2SZIKYrBLklQQg12SpIIY7JIkFcRglySpIFV/85w0FiJiAthD57eAPZaZ9424JUkaCh+xq1Trgf2ZuRFYN+pmJGlYDHaVahVwpHt7pndHRExGxK6fzPxs+F1JUsMMdpXqKJ1wh745z8zpzNxa6p9slbS8+Rq7SnUA2BMR64CHRt2MJA2Lwa4iZeZzwDWj7kOShs2n4iVJKojBLklSQQx2SZIKUinYI2IiIj4fEXdGxHt7tq+JiC9GxL6IWFN/m5LUbq6Paouqj9jn+6UfW4DN3Y8tNfUmSePE9VGtUPVd8auA73dv9/7SjxWZeQwgIlb0HxQRk8DkQB1K0nhY2vr4yrc136GWhaqP2Of7pR/HImJFRLwQONZ/0OwvBBmwR0kaB0tbH1/08mH0qGWg6iP2k37pR0RMZeYGOn9s49NAADvrbVGSxoLro1qhUrDP8Us/9nW3Pw5cVWNfkjRWXB/VFv7mOS1btx3/Mrcd//JQaj179sGh1BlFvbOeWTu0WpJOzevYJUkqiMEuSVJBDHZJkgpisEuSVBCDXZKkghjskiQVxGCXJKkgBrskSQUx2CVJKojBLklSQQx2SZIKYrCrWBFxQUTsjYj7R92LJA2Lwa5iZeYTmXntqPuQpGHyr7tp2YmISWBy1H1IUhN8xK5lJzOnM3PrqPuQpCYY7CpWRJwTEbcDF0XEzaPuR5KGodJT8RExAewBTgCPZeZ93e2fAF4NPAt8MjOfrLlPqbLMfBrYNOo+tHy4RqoNqj5iXw/sz8yNwLqe7SeA54HjwM9r6k2Sxo1rpEau6pvnVgHf796e6dm+IzNnIuKdwNXAbb0Hzb5Z6fJL4cBJe9SU/PGoOxhMvHLUHUhLUnmNPOnNnN+dGk6XKlrVR+xH6QzuScdm5uwAPwWs6D9o9s1Kq18+UI+SNC4qr5G+mVN1q/qI/QCwJyLWAQ9FxFRmboiIjwLnAS8Bbqi7SUkaE66RGrlKwZ6ZzwHX9Gza192+o86mJGkcuUaqDbzcTZKkghjskiQVxGCXJKkgBrskSQUx2CVJKoh/3U0agrOeWTvUes+efbDIWjD8r6U0bnzELklSQQx2SZIKYrBLklQQg12SpIIY7JIkFcRglySpIAa7JEkFMdglSSqIwS5JUkEMdkmSClI52CPigojYGxH3922/OCKmIuKeiFhZX4tSdRHxzoj4XER8NSIuGXU/Wh5cH9UGlYM9M5/IzGvn2HUdcDVwKzDXfmloMvPBzJydyStG3Y+WB9dHtUGdT8VHZiZwGDivxvNKS7EduGPUTWjZc33U0NT5190yIgI4HzjauyMiJoHJyy+tsZp0ChGxA3g0M7/Xt30SmBxNV1qmTrk+jqQrFWmQ19jPiYjbgYsi4uaImOru2gvcBXy4e/v/ZOZ0Zm5d/fKltistTkRsBi4D3h0Rm3r3zc7jaDpTyZayPg63U5Ws8iP2zHwa2DTH9oPAcP8wszSPzLwNuG3UfWh5cX1UG3i5myRJBTHYJUkqiMEuSVJBDHZJkgpisEuSVBCDXZKkghjskiQVxGCXJKkgBrskSQUx2CVJKkidfwRGUkuc9czaodV69uzh/qbUYdYb5tdRqouP2CVJKojBLklSQQx2SZIKYrBLklQQg12SpIIY7JIkFaTy5W4RcQGwHZjIzPf0bJ8Cfg38BtiSmcfralKSxoHro9qg8iP2zHwiM6+dY9evgASeBp5famOSNG5cH9UGdf6Cmg9m5kxE3ABcBjzSf4fdd3c+xk3+eNQdVBevHHUHknqccn2U6lJbsGfmTPfmU8CK3n0RMQlM1lVLksaJ66OGaZDX2M8BbgEuioibgTWZuSEidgFnAi8GTnoqKjOngemIuLGGniWplVwf1QaVgz0znwY2zbF9ay0dSTWIiDcB7wfOBe7KzAdH3JKWAddHtYGXu6lImfmdzNwEXAW8ZdT9SNKwGOwqVkRcCXwDeLhv+2T3qVFJKo7BrmJl5heA1wPX922f9qlRSaXy77GrSBFxOXAJMAF8acTtSNLQGOwqUmZ+BfjKqPuQpGHzqXhJkgpisEuSVBCDXZKkghjskiQVxGCXJKkgBrskSQUx2CVJKojBLklSQQx2SZIKYrBLklQQf6Wslq3Nv/Nn7JjYPJRaZz2zdih1RmHYn9uzZx8caj1p3PiIXZKkglQK9oh4Z0R8LiK+GhGX9Gy/OCKmIuKeiFhZf5uS1H6ukWqDSsGemQ9m5nXA1cAVPbtmt90KXFtfe5I0Plwj1QaDvsa+Hbij59+RmRkRh4Hz+u8cEZPA5IC1JGncLHqNdH1U3Sq/xh4RO4BHM/N7PZszIgI4Hzjaf0xmTmfm1sHblKTxUHWNdH1U3So9Yo+IzcBlwNkR8Srg9Zm5AdgL3AWcAWyru0lJGgeukWqDSsGembcBt/Vsur27/SDgNSiSljXXSLWBl7tJklQQg12SpIIY7JIkFcRgV7EiYiIivhsRfzrqXiRpWAx2lWwb8KVRNyFJw2Swq0gRcSnwOPDUHPsmI2LXT2Z+NvzGJKlhBrtKtbb7cRVwfe+O2V8Icv5pLxtJY5LUJP9sq4qUmR8GiIgNgA/NJS0bBruKlplTo+5BkobJp+IlSSqIwS5JUkEMdkmSCmKwS5JUEINdkqSCGOySJBXEYJckqSAGuyRJBan0C2oi4p3AO4CXAnsy85vd7VPAr4HfAFsy83jNfUpS67lGqg0qPWLPzAcz8zrgauCKnl2/AhJ4Gni+vvYkaXy4RqoNIjOrHxTxN8C9mfm97r9Py8yZiLgB+HFmPtJ3/0lgErgU+PrS257TK4DDY3Rezz2312bmmxs690ki4u8Z7PNo8vNfLrWGXW/QWq/IzHdVPajKGjnm62OT5x7Hnps+9+LWx8ys9AHsAC6ZZ997gD9f4NhdVetV6KuRc49jz5672Y9h9lhqrZI/t0HXyHH9/8q1t33nrvoa+2bgMuDsiHgV8PrM3BARu4AzgRcD1y5wiukq9Spq6tzj2LPnbtYweyy11rDrDaXWEtfIcf3/yrW3Zece6Kl4SZLUTl7uJklSQRr/e+wRsRLYCcwAd2fmt3r2TTHAJSARMQHsAU4Aj2Xmfd3ta4CP0PmB5ZbM/GHFXuc77yeAVwPPAp/MzCernLd7jguA7cBEZr6nZ/vFwAY634ubMvO/ajz3FEu8xGaBy3fq6HusLg2abz4arDfn97WhWnN+Lxqq9Sbg/cC5wF2Z+WBTtbr1JoB/BrZn5tearFXVOK2Ppzj3J1iGa2Rb18dhPGL/AJ03k1wNbOzbN+glIOuB/Zm5EVjXs30LsLn7sWWAXuc774luf8eBnw9wXjLzicyc67W12UtjbmXh9ycMcu4lX2KT81++U0ff43Zp0Hzz0YgFvq9N1Jrve9FEre9k5ibgKuAtTdbq2gZ8aQh1BjFO6+NC516Wa2Rb18dagz0iLoyIh3s/gFXAkcycmeOQD3YH5L/pvOFksVYBR7q3e8+7IjOPZeYvgBUDfArznXdHZl4JfJPOF7lOkZ03OhwGzqv53IN+feeyHbij59919t1/7jr7rtN881GS/u9FIyLiSuAbwMMN17kUeBx4qsk6i+xl3NfHhc693NfIVq2PtT4Vn5k/AN7euy0iPg6siogfzXH/2cF4imqDdpTOgD3OyT+cHIuIFUAAxyqcb8Hz9vX5BwOcdyEZEQGc361f34kH//qeJCJ2AI9m95rc2dPX0fdc566r7wbMN3dFmOf73IjM/EJE3AvcD/xTg6XWAmcBvw/8EhjZU/EFrI/znns5r5FtXB8bf1d8RJxL5+mIE8A9mXkwIqbmugQkM3+5yHPOvs5zHPg28Lbu+V4D3ERncHdm5uMVe53vvB+l81PXS4AbBny95BzgFuCtwJ3Amu651wLvA84Atg342tR85x7o69t37s10nlb6N+Df+f/Ld+roe75zL7nvJvTPR2bua7jeSd/XzNzZYK2TvheZeXuDtS4HLgEmgEcyc39TtXpqbgB+1sLX2MdmfTzFuZflGtnW9dHL3SRJKkhxTydKkrScGeySJBXEYJckqSAGuyRJBTHYJUkqiMEuSVJBDHZJkgpisEuSVBCDXZKkghjskiQVxGCXJKkgBrskSQUx2CVJKojBLklSQSoHe0RcEBF7I+L+vu0XR8RURNwTESvra1Gan/OoNnEe1QaVgz0zn8jMa+fYdR1wNXArMNd+qXbOo9rEeVQb1PlUfGRmAoeB82o8rzQI51Ft4jxqaE6v8VwZEQGcDxzt3RERk8DkG9/4xhtf97rX1VhSpdm9e/eBzHxXDadyHrVkzqPaZLHzGJ0fIhcvIs4BbgHeCtwJrMnMDRGxFngfcAawLTOf7D9269atuWvXrkr1tLxExO7M3Frh/s6jGuM8qk0WO4+VH7Fn5tPApjm2HwQOVj2ftBTOo9rEeVQbeLmbJEkFMdglSSqIwS5JUkEMdkmSCmKwS5JUEINdkqSCGOySJBXEYJckqSAGuyRJBTHYJUkqiMEuSVJBDHZJkgpisEuSVBCDXZKkghjskiQVxGCXJKkgBrskSQUx2CVJKojBLklSQQx2SZIKYrBLklQQg12SpIKcXuXOETEB7AFOAI9l5n3d7ZcB1wAJ3JWZX6+7Uamf86g2cR7VFlUfsa8H9mfmRmBdz/Y3A9uALcAlNfUmnYrzqDZxHtUKVYN9FXCke3umZ/tXgLuBB4B7+w+KiMmI2HXo0KFBepTm4zyqTZxHtULVYD9KZ3j7j72Jzk+ia+n8ZHqSzJzOzK2rV68epEdpPs6j2sR5VCtUeo0dOADsiYh1wEMRMZWZG4B/AO6iM8xfq7dFaV7Oo9rEeVQrVAr2zHyOzptAZu3rbr+XOZ5ikprkPKpNnEe1hZe7SZJUEINdkqSCGOySJBXEYJckqSAGuyRJBTHYJUkqiMEuSVJBDHZJkgpisEuSVBCDXZKkghjskiQVxGCXJKkgBrskSQUx2CVJKojBLklSQQx2SZIKYrBLklQQg12SpIIY7JIkFcRglySpIAa7JEkFOb3KnSNiAtgDnAAey8z7uttXAh8BXgDcl5nfrrtRqZ/zqDZxHtUWVR+xrwf2Z+ZGYF3P9q3AL7vn+2lNvUmn4jyqTZxHtULVYF8FHOnenunZfiEwBWwHPrb0tqRFcR7VJs6jWqFqsB+lM7z9xx4FngGOAWf2HxQRkxGx69ChQ4P0KM3HeVSbOI9qharBfgC4IiI+CzwUEVPd7buAncDngNv7D8rM6czcunr16iW0Kv0W51Ft4jyqFSq9eS4znwOu6dm0r7v9h8CG+tqSTs15VJs4j2oLL3eTJKkgBrskSQUx2CVJKojBLklSQQx2SZIKYrBLklQQg12SpIIY7JIkFcRglySpIAa7JEkFMdglSSqIwS5JUkEMdkmSCmKwS5JUEINdkqSCGOySJBXEYJckqSAGuyRJBTHYJUkqiMEuSVJBDHZJkgpisEuSVJBKwR4RExHx+Yi4MyLe27fvwoh4KiLOrLdFaW7Oo9rGmVQbVH3Evh7Yn5kbgXWzGyPiDOADwKM19iadivOotnEmNXJVg30VcKR7e6Zn+4eATwE510ERMRkRuw4dOlS5QWkBzqPapvJMOo+qW9VgP0pncPuPvQi4CXgDcH3/QZk5nZlbV69ePUiP0nycR7VN5Zl0HlW3qsF+ALgiIj4LPBQRUwCZuT4zNwH/Cuypt0VpXs6j2saZ1MidXuXOmfkccE3Ppn19+zfU0JO0KM6j2saZVBt4uZskSQUx2CVJKojBLklSQQx2SZIKYrBLklQQg12SpIIY7JIkFcRglySpIAa7JEkFMdglSSqIwS5JUkEMdkmSCmKwS5JUEINdkqSCGOySJBXEYJckqSAGuyRJBTHYJUkqiMEuSVJBDHZJkgpisEuSVJDTq9w5IiaAPcAJ4LHMvK+7/WbgVcDvApsy88m6G5X6OY9qG2dSbVD1Eft6YH9mbgTWzW7MzJ2ZeR1wN/DHNfYnLcR5VNs4kxq5qsG+CjjSvT3Tu6P7k+q7gYdr6EtaDOdRbeNMauSqBvtROoN70rERsQL4DHBzZh7rPygiJiNi16FDhwbtU5qL86i2qTyTzqPqVjXYDwBXRMRngYciYqq7fS/wUuBjEbG2/6DMnM7MratXr15Kr1I/51FtU3kmnUfVrdKb5zLzOeCank37utuvqLMpaTGcR7WNM6k28HI3SZIKYrBLklQQg12SpIIY7JIkFcRglySpIAa7JEkFMdglSSqIwS5JUkEMdkmSCmKwS5JUEINdkqSCGOySJBXEYJckqSAGuyRJBTHYJUkqiMEuSVJBDHZJkgpisEuSVBCDXZKkghjskiQVxGCXJKkgBrskSQWpFOwRMRERn4+IOyPivT3b10TEFyNiX0Ssqb9N6bc5j2oT51FtUfUR+3pgf2ZuBNb1bN8CbO5+bKmpN+lUnEe1ifOoVji94v1XAd/v3p7p2b4iM48BRMSK/oMiYhKYBP5j9+7dXx+k0QG8Ajg8pFrDrldqLYDXVriv89iOeqXWAudxHOuV/Lktah6rBvtROsP7OCc/2j/WHdgAjvUflJnTwHRE7MrMrRVrDmSYtYZdr9Ras/Uq3N15bEG9UmvN1qtwd+exBfVK/9wWc7+qwX4A2BMR64CHImIqMzcAe4BP0xncnQscP12x3lIMs9aw65Vaq2o957Ed9UqtVbWe89iOesv+c4vMbLoRSZI0JF7uJklSQRoL9mFe+rFArZsj4nMR8WBEnFtHrYXqdfddGBFPRcSZTdaKiJUR8amI+ExEvLnhWpdFxP6IeCAiLq2jVve8F0TE3oi4v2/7xRExFRH3RMTKmmo5jw3Wch4r13IeG6y17OcxMxv5AN4PXNa9fX/P9juAFcCLgDuarNWz/3LgvUP43M4A/hb4O+DMhmv9NXAr8Fng9xqudQtwAbAS+KsGZuX+vn/vo/N65GuAjzmPzqPz6Dw6j4ufxyafil8FHOne/q1LPzLzF3QGuMlaRMQE8G7g4ZpqLVTvQ8CngDrfuDBfrQuBKWA78LGGa30FuBt4ALi3ploLiexM8GHgvJrO6Tw2W8t5rMZ5bLbWsp7HJoN99tKP/jrHImJFRLyQOS79qLNWdC4x+Qxwc3avI22yHnARcBPwBuD6hmsdBZ6h8zWs5WmtBWrdBFwCrAW21VRrIRkRAZzf7akOzmOztZzHapzHZmst63ls7F3x3Z8E9wDHgW8Db8vMDRHxGjpfiAB2ZubjDdZ6AJig81PWA5l5cKm1FqrXs38K2JSZ/9NUre7rbzd377Y3M/+lwVp/AVxKZ5j/MTO/sNRa3Xrn0Hka663AncCabr21wPvoPHW3LTOfrKGW8+g8nqqe81gD53H08+jlbpIkFcTL3SRJKojBLklSQQx2SZIKYrBLklQQg12SpIL8LxVsbPMF9mHMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 600x400 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmap = colors.ListedColormap(\n",
    "    ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "     '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "norm = colors.Normalize(vmin=0, vmax=9)\n",
    "\n",
    "fig, axs = plt.subplots(2, len(correct), figsize=(4*len(correct),8), dpi=50)\n",
    "for n, i in enumerate(correct):\n",
    "    axs[0][n].imshow(i, cmap=cmap, norm=norm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'detach'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-318-cdcfd8d35378>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtask_losses\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-318-cdcfd8d35378>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtask_losses\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'detach'"
     ]
    }
   ],
   "source": [
    "plt.plot([list(i.detach().numpy()) for i in task_losses])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
